{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to start working on modelling the states without the gdp index. We will try to keep to approach as modular as possible, in case we need to change the selected dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = abs(pd.read_csv('Correlation_matrix.csv'))*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will always take the absolute value of the round of 10 correlation between states. First let us focus on swing states. We will need to select the swing state based on sources **previous to the 2020 election**. Source selected: https://fr.wikipedia.org/wiki/Swing_state#Historique (last modification: 24 october 2020).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big problem will be the way we will construct the validation set. It needs to be from the swing state considered. How can we prevent the creation of a deterministic validation set while imposing such a constraint ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Getting a list of states and swing states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing_states = ['Texas', 'Florida', 'Ohio', 'Georgia', 'North Carolina', 'Arizona', 'Iowa', 'Pennsylvania', 'Michigan', 'Virginia', 'Minnesota', 'Wisconsin', 'Colorado', 'Nevada', 'New Hampshire']\n",
    "all_states = []\n",
    "index_swing_states = []\n",
    "for i, file in enumerate(os.listdir('states/')):\n",
    "    state = file.split('.')[0]\n",
    "    all_states.append(state)\n",
    "    if state in swing_states:\n",
    "        index_swing_states.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct the base dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([pd.read_csv('states/'+file) for file in os.listdir('states/')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Important modification to prevent information leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['republican']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_9</th>\n",
       "      <th>republican</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rep_House_Prop</th>\n",
       "      <th>State</th>\n",
       "      <th>Result</th>\n",
       "      <th>rep_loyalty</th>\n",
       "      <th>popular_vote_percentage</th>\n",
       "      <th>density</th>\n",
       "      <th>RDI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.380492</td>\n",
       "      <td>56.679982</td>\n",
       "      <td>53.953977</td>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>53.370</td>\n",
       "      <td>76.757225</td>\n",
       "      <td>52087.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.175509</td>\n",
       "      <td>41.956795</td>\n",
       "      <td>44.865857</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>37.450</td>\n",
       "      <td>78.959026</td>\n",
       "      <td>56035.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.410314</td>\n",
       "      <td>46.671015</td>\n",
       "      <td>45.734410</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.720</td>\n",
       "      <td>81.841997</td>\n",
       "      <td>60091.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.511963</td>\n",
       "      <td>53.115390</td>\n",
       "      <td>51.697343</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.870</td>\n",
       "      <td>84.927856</td>\n",
       "      <td>64078.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.096244</td>\n",
       "      <td>56.892984</td>\n",
       "      <td>56.020586</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.730</td>\n",
       "      <td>86.426359</td>\n",
       "      <td>68482.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44.975058</td>\n",
       "      <td>45.307159</td>\n",
       "      <td>45.169505</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.720</td>\n",
       "      <td>4.907941</td>\n",
       "      <td>7673.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.684991</td>\n",
       "      <td>61.311713</td>\n",
       "      <td>58.457317</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.870</td>\n",
       "      <td>5.053262</td>\n",
       "      <td>8155.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.828129</td>\n",
       "      <td>60.276110</td>\n",
       "      <td>60.148473</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.660</td>\n",
       "      <td>5.582234</td>\n",
       "      <td>9154.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.320477</td>\n",
       "      <td>60.283224</td>\n",
       "      <td>57.678128</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.090</td>\n",
       "      <td>5.985616</td>\n",
       "      <td>10109.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66.209900</td>\n",
       "      <td>62.336910</td>\n",
       "      <td>66.226278</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.525</td>\n",
       "      <td>5.796735</td>\n",
       "      <td>10593.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_10   month_11    month_9  republican  Year  Rep_House_Prop  \\\n",
       "0   56.380492  56.679982  53.953977           1  1988        0.285714   \n",
       "3   42.175509  41.956795  44.865857           1  1992        0.285714   \n",
       "5   45.410314  46.671015  45.734410           1  1996        0.428571   \n",
       "7   52.511963  53.115390  51.697343           1  2000        0.714286   \n",
       "8   57.096244  56.892984  56.020586           1  2004        0.714286   \n",
       "..        ...        ...        ...         ...   ...             ...   \n",
       "5   44.975058  45.307159  45.169505           1  1996        1.000000   \n",
       "7   59.684991  61.311713  58.457317           1  2000        1.000000   \n",
       "9   58.828129  60.276110  60.148473           1  2008        1.000000   \n",
       "10  57.320477  60.283224  57.678128           1  2016        1.000000   \n",
       "12  66.209900  62.336910  66.226278           1  2020        1.000000   \n",
       "\n",
       "      State  Result  rep_loyalty  popular_vote_percentage    density       RDI  \n",
       "0   Alabama       1          0.8                   53.370  76.757225  52087.05  \n",
       "3   Alabama       1          0.9                   37.450  78.959026  56035.35  \n",
       "5   Alabama       1          1.0                   40.720  81.841997  60091.59  \n",
       "7   Alabama       1          1.0                   47.870  84.927856  64078.92  \n",
       "8   Alabama       1          1.0                   50.730  86.426359  68482.42  \n",
       "..      ...     ...          ...                      ...        ...       ...  \n",
       "5   Wyoming       1          1.0                   40.720   4.907941   7673.05  \n",
       "7   Wyoming       1          1.0                   47.870   5.053262   8155.73  \n",
       "9   Wyoming       1          1.0                   45.660   5.582234   9154.98  \n",
       "10  Wyoming       1          1.0                   46.090   5.985616  10109.96  \n",
       "12  Wyoming       1          1.0                   46.525   5.796735  10593.19  \n",
       "\n",
       "[444 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_importance_dfs = {}\n",
    "for index_state in index_swing_states:  # model only for the swing states\n",
    "    data_swing_state = []\n",
    "    for i, state in enumerate(all_states):  \n",
    "        if state == all_states[index_state]:\n",
    "            continue\n",
    "        if state != all_states[index_state]:   # for all the state but the swing state, remove the 2020 election\n",
    "            data_state = final_df[final_df['State'] == state]\n",
    "            data_state = data_state.iloc[:-2, :]\n",
    "        correlation = int(correlation_matrix.iloc[index_state, i])\n",
    "        if correlation > 0:  # add correlation * the dataframe for the state (where we removed the 2020 election)\n",
    "            data_state_importance = pd.concat([data_state for _ in range(correlation)])\n",
    "            if data_state.values.tolist():\n",
    "                try:\n",
    "                    data_swing_state = pd.concat([data_swing_state, data_state_importance])\n",
    "                except:\n",
    "                    data_swing_state = data_state_importance\n",
    "    final_importance_dfs[all_states[index_state]] = data_swing_state\n",
    "# for every swing state, the corresponding values are missing, this is in order to help for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_9</th>\n",
       "      <th>republican</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rep_House_Prop</th>\n",
       "      <th>State</th>\n",
       "      <th>Result</th>\n",
       "      <th>rep_loyalty</th>\n",
       "      <th>popular_vote_percentage</th>\n",
       "      <th>density</th>\n",
       "      <th>RDI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.380492</td>\n",
       "      <td>56.679982</td>\n",
       "      <td>53.953977</td>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>53.37</td>\n",
       "      <td>76.757225</td>\n",
       "      <td>52087.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.175509</td>\n",
       "      <td>41.956795</td>\n",
       "      <td>44.865857</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>37.45</td>\n",
       "      <td>78.959026</td>\n",
       "      <td>56035.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.410314</td>\n",
       "      <td>46.671015</td>\n",
       "      <td>45.734410</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.72</td>\n",
       "      <td>81.841997</td>\n",
       "      <td>60091.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.511963</td>\n",
       "      <td>53.115390</td>\n",
       "      <td>51.697343</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.87</td>\n",
       "      <td>84.927856</td>\n",
       "      <td>64078.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.096244</td>\n",
       "      <td>56.892984</td>\n",
       "      <td>56.020586</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.73</td>\n",
       "      <td>86.426359</td>\n",
       "      <td>68482.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.103222</td>\n",
       "      <td>57.584084</td>\n",
       "      <td>44.480604</td>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.37</td>\n",
       "      <td>4.754759</td>\n",
       "      <td>7002.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.404081</td>\n",
       "      <td>34.254117</td>\n",
       "      <td>34.109462</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.45</td>\n",
       "      <td>4.738300</td>\n",
       "      <td>7243.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44.975058</td>\n",
       "      <td>45.307159</td>\n",
       "      <td>45.169505</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.72</td>\n",
       "      <td>4.907941</td>\n",
       "      <td>7673.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.684991</td>\n",
       "      <td>61.311713</td>\n",
       "      <td>58.457317</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.87</td>\n",
       "      <td>5.053262</td>\n",
       "      <td>8155.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.828129</td>\n",
       "      <td>60.276110</td>\n",
       "      <td>60.148473</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.66</td>\n",
       "      <td>5.582234</td>\n",
       "      <td>9154.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_10   month_11    month_9  republican  Year  Rep_House_Prop  \\\n",
       "0   56.380492  56.679982  53.953977           1  1988        0.285714   \n",
       "3   42.175509  41.956795  44.865857           1  1992        0.285714   \n",
       "5   45.410314  46.671015  45.734410           1  1996        0.428571   \n",
       "7   52.511963  53.115390  51.697343           1  2000        0.714286   \n",
       "8   57.096244  56.892984  56.020586           1  2004        0.714286   \n",
       "..        ...        ...        ...         ...   ...             ...   \n",
       "0   50.103222  57.584084  44.480604           1  1988        1.000000   \n",
       "3   33.404081  34.254117  34.109462           1  1992        1.000000   \n",
       "5   44.975058  45.307159  45.169505           1  1996        1.000000   \n",
       "7   59.684991  61.311713  58.457317           1  2000        1.000000   \n",
       "9   58.828129  60.276110  60.148473           1  2008        1.000000   \n",
       "\n",
       "      State  Result  rep_loyalty  popular_vote_percentage    density       RDI  \n",
       "0   Alabama       1          0.8                    53.37  76.757225  52087.05  \n",
       "3   Alabama       1          0.9                    37.45  78.959026  56035.35  \n",
       "5   Alabama       1          1.0                    40.72  81.841997  60091.59  \n",
       "7   Alabama       1          1.0                    47.87  84.927856  64078.92  \n",
       "8   Alabama       1          1.0                    50.73  86.426359  68482.42  \n",
       "..      ...     ...          ...                      ...        ...       ...  \n",
       "0   Wyoming       1          1.0                    53.37   4.754759   7002.49  \n",
       "3   Wyoming       1          1.0                    37.45   4.738300   7243.74  \n",
       "5   Wyoming       1          1.0                    40.72   4.907941   7673.05  \n",
       "7   Wyoming       1          1.0                    47.87   5.053262   8155.73  \n",
       "9   Wyoming       1          1.0                    45.66   5.582234   9154.98  \n",
       "\n",
       "[1203 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_importance_dfs['Texas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling part : swing state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the swing state you wish to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing_state = 'Texas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(initial_df, final_importance_df, swing_state): # particular state missing\n",
    "    swing_state_data = initial_df[initial_df['State'] == swing_state]  # data to be protected\n",
    "    data_test = swing_state_data[swing_state_data['Year'] == 2020].iloc[:1, :] # test data\n",
    "    X_test, y_test = data_test.drop('Result', axis=1), data_test['Result'] # X test and test labels  \n",
    "    swing_state_data = swing_state_data[swing_state_data['Year'] != 2020] # we remove the test data\n",
    "    X_train, X_val = train_test_split(swing_state_data, train_size = 0.7)\n",
    "    X_val, y_val = X_val.drop('Result', axis=1), X_val['Result']\n",
    "    df_corr_to_concat = pd.concat([X_train for _ in range(10)])\n",
    "    X_values = pd.concat((final_importance_df[final_importance_df['State'] != swing_state], df_corr_to_concat))\n",
    "    X_values = X_values.sample(frac=1, replace=False) \n",
    "    X, y = X_values.drop('Result', axis=1), X_values['Result']\n",
    "    return X, X_val, X_test, y, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split(final_df, final_importance_dfs[swing_state], swing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(X_train, X_val, y_train, y_val, models, scaler=True, Poly=1, PCA_comp=0):\n",
    "    # pca is the total variance explained required. 0 means that we do not want to perform pca\n",
    "    if 'State' in X_train.columns:\n",
    "        X_train = X_train.drop('State', axis=1)\n",
    "        X_val = X_val.drop('State', axis=1)\n",
    "    if 'Year' in X_train.columns:\n",
    "        X_train = X_train.drop('Year', axis=1)\n",
    "        X_val = X_val.drop('Year', axis=1)\n",
    "    if 'republican' in X_train.columns:\n",
    "        X_train = X_train.drop('republican', axis=1)\n",
    "        X_val = X_val.drop('republican', axis=1)\n",
    "    if PCA_comp > 0 and not scaler:\n",
    "        raise ValueError('We must normalize before performing PCA')\n",
    "    # if PCA_comp > 1 and Poly > 1:\n",
    "        # print('Performing Polynomial Transformation on top of PCA ...')\n",
    "    if scaler:\n",
    "        # print('Normalizing the data ...')\n",
    "        scaler = MinMaxScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "    if PCA_comp > 0:\n",
    "        # print('Performing PCA ...')\n",
    "        pca = PCA(n_components=X_train.shape[1])\n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_val = pca.transform(X_val)\n",
    "        total_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "        for i, variance in enumerate(total_variance):\n",
    "            if variance > PCA_comp:\n",
    "                break \n",
    "        X_train, X_val = X_train[:, :i+1], X_val[:, :i+1]\n",
    "    if Poly > 1:\n",
    "        # print('Polynomial transformation ...')\n",
    "        poly_features = PolynomialFeatures(degree=Poly, include_bias=False).fit(X_train)\n",
    "        X_train = poly_features.transform(X_train)\n",
    "        X_val = poly_features.transform(X_val)\n",
    "    accuracies = []\n",
    "    auc = []\n",
    "    # print('Modelling and gathering the predictions ..')\n",
    "    for i, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_val)\n",
    "        accuracies.append(accuracy_score(y_val, predictions))\n",
    "        try:\n",
    "            auc.append(roc_auc_score(y_val, predictions))\n",
    "        except ValueError:\n",
    "            auc.append(1)\n",
    "    return models, accuracies, auc, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, accuracies, auc, predictions = modelling(X_train, X_val, y_train, y_val, models=[LogisticRegression()], scaler=True, Poly=2, PCA_comp=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tying it all together for the modelling framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy over all of the swing states is 0.7333333333333333 and is obtained with LogisticRegression()\n",
      "The best auc over all of the swing states is 0.8666666666666667 and is obtained with LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "models_considered = [LogisticRegression(), DecisionTreeClassifier()]\n",
    "F1, acc, auc = [], [], []\n",
    "for state in swing_states:\n",
    "    # inspecting that everything is okay \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split(final_df, final_importance_dfs[state], state)\n",
    "    models, accuracies, aucs, predictions = modelling(X_train, X_val, y_train, y_val, models=models_considered, scaler=True, Poly=2, PCA_comp=0.9)\n",
    "    acc.append(accuracies)\n",
    "    auc.append(aucs)\n",
    "acc_mean, auc_mean = np.mean(np.array(acc), axis=0), np.mean(np.array(auc), axis=0)\n",
    "print('The best accuracy over all of the swing states is ' + str(np.max(acc_mean)) + ' and is obtained with ' + str(models_considered[np.argmax(acc_mean)]))\n",
    "print('The best auc over all of the swing states is ' + str(np.max(auc_mean)) + ' and is obtained with ' + str(models_considered[np.argmax(auc_mean)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
